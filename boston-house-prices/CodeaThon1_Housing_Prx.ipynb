{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "#a definition of the column names\n",
    "\"\"\"    - CRIM     per capita crime rate by town\n",
    "    - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    - INDUS    proportion of non-retail business acres per town\n",
    "    - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) ###note, a factor shouldn't be numeric\n",
    "    - NOX      nitric oxides concentration (parts per 10 million)\n",
    "    - RM       average number of rooms per dwelling\n",
    "    - AGE      proportion of owner-occupied units built prior to 1940\n",
    "    - DIS      weighted distances to five Boston employment centres\n",
    "    - RAD      index of accessibility to radial highways                             ###another category\n",
    "    - TAX      full-value property-tax rate per $10,000\n",
    "    - PTRATIO  pupil-teacher ratio by town\n",
    "    - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "    - LSTAT    % lower status of the population\n",
    "    - MEDV     Median value of owner-occupied homes in $1000's\"\"\"\n",
    "    \n",
    "def process_data(data):\n",
    "    return(data)\n",
    "\n",
    "data1 = pd.read_csv(\"housing.csv\",sep=\"\\s+\")\n",
    "data1.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6fb6900621c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#more data processing, shows there are no null values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#more data processing, shows there are no null values\n",
    "print(data.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4fd82b71bbec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mSSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2adj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcori\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mSSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR2adj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcori\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstat_cal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalcor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def stat_cal(df, i, split_ratio, calcor = True, drop = True):\n",
    "    cori = -1\n",
    "    if calcor:\n",
    "        ex = df[i].mean()\n",
    "        ey = df[\"MEDV\"].mean()\n",
    "        ox = np.sqrt(sum([(x - ex)**2 for x in df[i]]))\n",
    "        oy = np.sqrt(sum([(y - ey)**2 for y in df[\"MEDV\"]]))\n",
    "        cori = np.sum([(x*y - ex*ey)/(ox*oy) for (x, y) in zip(df[i], df[\"MEDV\"])])\n",
    "        \n",
    "    if drop:\n",
    "        df = df.drop(i, axis = 1)\n",
    "        \n",
    "    n = int(df.shape[0]*split_ratio)\n",
    "    Xtrain = df.iloc[n:].drop(\"MEDV\", axis = 1)\n",
    "    Xtrain.insert(0, 'ONE', [1]*(df.shape[0] - n))#don't include test cases\n",
    "    Ytrain = df.loc[n:,\"MEDV\"]\n",
    "    \n",
    "    Xtest = df.iloc[:n,:].drop(\"MEDV\", axis = 1)\n",
    "    Xtest.insert(0, 'ONE', [1]*(n))#don't include test cases\n",
    "    Ytest = df.loc[:n-1,\"MEDV\"]\n",
    "    \n",
    "    theta = np.linalg.inv(Xtrain.T.dot(Xtrain)).dot(Xtrain.T).dot(Ytrain)\n",
    "\n",
    "    SSE = sum((Xtest.dot(theta) - Ytest)**2)\n",
    "    SST = sum((Ytest - np.mean(Ytest))**2)\n",
    "    R2 = 1 - SSE/SST\n",
    "    R2adj = 1 - (SSE/(Xtrain.shape[0] - Xtrain.shape[1] - 1))/(SST/(Xtrain.shape[0] - 1))#adjust both SSE,SST for df\n",
    "        \n",
    "    \n",
    "    return SSE, SST, R2, R2adj, cori\n",
    "SSE, SST, R2, R2adj, cori = stat_cal(data, i, 0.2, calcor = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ba71c99a5458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#scrape code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#should just make a fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MEDV\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ONE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#don't include test cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mYtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"MEDV\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "    #scrape code\n",
    "    #should just make a fn\n",
    "    X1 = data.iloc[100:].drop([i, \"MEDV\"], axis = 1)\n",
    "    X1.insert(0, 'ONE', [1]*(data.shape[0] - 100))#don't include test cases\n",
    "    Ytrain = data.loc[100:,\"MEDV\"]\n",
    "    Xtest = data.iloc[:100,:].drop([i,\"MEDV\"], axis = 1)\n",
    "    Xtest.insert(0, 'ONE', [1]*100)#don't include test cases\n",
    "    Ytest = data.loc[:100,\"MEDV\"]\n",
    "    theta = np.linalg.inv(X1.T.dot(X1)).dot(X1.T).dot(Ytrain)\n",
    "    SSE = sum((Xtest.dot(theta) - Ytest)**2)\n",
    "    SST = sum((Ytest - np.mean(Ytest))**2)\n",
    "    R2 = 1 - SSE/SST\n",
    "    R2adj = 1 - (SSE/(X1.shape[0] - X1.shape[1] - 1))/(SST/(X1.shape[0] - 1))#adjust both SSE,SST for df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-17289298f15c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"housing.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\s+\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'CRIM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ZN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'INDUS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CHAS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NOX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DIS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RAD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TAX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PTRATIO'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'B'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LSTAT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MEDV'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = pd.read_csv(\"housing.csv\",sep=\"\\s+\")\n",
    "data.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "corrs = data.corr()[\"MEDV\"]\n",
    "corr_indx = corrs.apply(abs).sort_values(ascending = False)[1:].index#drops the \"MEDV\", the y\n",
    "data.plot(x = corrs.index[0], y = corrs.index[1], kind = \"scatter\", alpha = 0.5,\n",
    "         c = data[\"MEDV\"], cmap = plt.get_cmap(\"jet\"), title = \"best correlated  values vs. MEDV\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 4, figsize = (12,12))\n",
    "fig.title = \"asdf\"\n",
    "rw_loc = 0\n",
    "col_loc = 0 \n",
    "\n",
    "data_SSE, data_SST = stat_cal(data, i, 0.2, calcor = False, drop = False)[:2]\n",
    "\n",
    "for i in corr_indx[:-1]:#eleven factors\n",
    "    #print(rw_loc, col_loc)\n",
    "    #print(ax[rw_loc, col_loc].plot(list(range(10)), list(range(10))))\n",
    "    fign = ax[rw_loc, col_loc] \n",
    "    fign.scatter(data[i], data[\"MEDV\"], alpha = 0.2)\n",
    "    fign.axes.get_xaxis().set_visible(False)\n",
    "    fign.axes.get_yaxis().set_visible(True)\n",
    "    fign.set_ylabel('MEDV')\n",
    "    fign.set_yticklabels([])\n",
    "    fign.frame_on = False\n",
    "    fign.set_title(i+ \" vs. $$$\", fontsize = 14)\n",
    "    fign.text(0.5, -0.05, 'corr: ' + str(\"%.3f\" % corrs[i]), horizontalalignment='center',\n",
    "              verticalalignment='center', transform=fign.transAxes)\n",
    "    line = sm.OLS(data[\"MEDV\"],sm.add_constant(data[i])).fit()\n",
    "    fign.plot(data[i], line.params[0] + line.params[1]*data[i],'r')\n",
    "    #next step is to add the amount of unique variance explained by this factor\n",
    "    SSE, SST, R2, R2adj, cori = stat_cal(data, i, 0.2, drop = True)\n",
    "    print(SSE, SST, R2, R2adj, cori, i)\n",
    "    iSSE, iSST = stat_cal(data.loc[:,[i, \"MEDV\"]], i, 0.2, drop = False)[:2]\n",
    "    #math below is wrong, need to update\n",
    "    print(\"Variance explained: \", cori)#variance explained by everthing(prediction on all others + noise) but this factor/total error\n",
    "    print(\"Uniquly explain % of total explained Variance\", ((data_SST - data_SSE) - SSE)/(data_SST))\n",
    "    print(i, R2, R2adj, SSE, SST)\n",
    "    \n",
    "    col_loc += 1\n",
    "    col_loc %= 4\n",
    "    if col_loc == 0:\n",
    "        rw_loc += 1\n",
    "        \n",
    "fig.suptitle('Plot of attributes vs. Home Value', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how being along the chase river changes the price distribution? Graphically\n",
    "#next plot pdfs of (feature, price). 3d\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "#how to calculate the pdf of this function\n",
    "i = 'LSTAT'\n",
    "pnts_d = [[x, y] for x,y in zip(data.loc[:,i], data.loc[:,\"MEDV\"])]\n",
    "#print(pnts_d)\n",
    "#doesn't work yet either\n",
    "joint_prob, edges = np.histogramdd(pnts_d[:30], bins = 3)\n",
    "\n",
    "ax.scatter(data[:,i], data[:,\"MEDV\"], zs = data[\"MEDV\"], alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(3, 3)[0]\n",
    "#list([data.iloc[:3,1], data.iloc[:3,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#how to include this in some pipeline?\n",
    "#######################ONLY run once\n",
    "cat_encoder = OneHotEncoder(sparse = False)\n",
    "cat_var_names = [\"RAD\",\"CHAS\"]\n",
    "cat_vars = data1[cat_var_names]\n",
    "housing_cat1hot = cat_encoder.fit_transform(cat_vars)#represents 11 binary columns of \"YES/NO\" for a specific radial then chase river  \n",
    "\n",
    "cat_names = []\n",
    "for i in range(len(cat_encoder.categories_)):\n",
    "    for j in cat_encoder.categories_[i]:\n",
    "        cat_names.append(str(cat_var_names[i]) + str(int(j)))\n",
    "\n",
    "cats = pd.DataFrame(data = housing_cat1hot, columns = cat_names)\n",
    "data1 = pd.merge(data1, cats, left_on=data1.index, right_on=cats.index,how='left')\n",
    "cat_var_names.append(\"key_0\")#gets included w/ merge\n",
    "data1.drop(labels = cat_var_names, axis = 1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should make this a pipeline\n",
    "def cat_vars(lst):\n",
    "    out = []\n",
    "    for i in lst:\n",
    "        cat_vars= data1[[i]]\n",
    "        cat_encoder = OneHotEncoder(sparse = False)\n",
    "        housing_cat1hot = cat_encoder.fit_transform(cat_vars)\n",
    "        out.append(housing_cat1hot)\n",
    "    return(out)\n",
    "cat_atts = [\"RAD\", \"CHAS\"]\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline = ColumnTransformer([(\"cat\", OneHotEncoder(), cat_atts)])\n",
    "data2 = full_pipeline.fit_transform(data1)#just has catagorical variables? figure this out. Are the columns of arrays or many columns?\n",
    "print(data1.shape)\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#do I need to keep a segment of data away from the rest perminantly?\n",
    "from sklearn.linear_model import LinearRegression\n",
    "y = data[\"MEDV\"]\n",
    "X = data.drop(\"MEDV\", axis = 1)\n",
    "X.insert(0,'ONE',[1]*X.shape[0])#prepend column of one's  for theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually calculate the best linear regression\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "SSE = sum((y - X.dot(theta))**2)\n",
    "SST = sum((y - np.sum(y))**2)\n",
    "R2 = 1 - SSE/SST\n",
    "print(R2)#very good fit, but included too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "theta = np.linalg.inv(x_train.T.dot(x_train)).dot(x_train.T).dot(y_train)\n",
    "SSE = sum((y_test - x_test.dot(theta))**2)\n",
    "SST = sum((y_test - sum(y_test))**2)\n",
    "R2 = 1 - SSE/SST\n",
    "print(\"R2: \", R2)#this is >0.99999? why? regardless of how much I split my test data? need to adj R^2\n",
    "MSE = SSE/(X.shape[0] - X.shape[1])#added the theta0 parameter for MEDV which was taken out\n",
    "print(\"MSE: \", MSE)\n",
    "Radj = 1 - MSE/(np.std(y_test)**2)\n",
    "print(\"Radj\", Radj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatically build model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "reg = lin_reg.fit(x_train, y_train)\n",
    "print(\"reg score: \", reg.score(x_test, y_test))#why does this perform much worse than Radj?\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE: \", mean_squared_error(y_test, x_test.dot(reg.coef_) + reg.intercept_))\n",
    "np.mean((x_test.dot(reg.coef_) + reg.intercept_ - y_test)**2)\n",
    "#the reason you have to include reg.intercept_ despite having the column of 1's in X is that theta0\n",
    "#in the regession = 0, as that term has no impact on the final outcome of the equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "forest_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forrest_scores = cross_val_score(forest_reg, x_train, y_train\n",
    "                                scoring=\"neg_mean_squared_error\", cv =10)\n",
    "forest_rsme_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
